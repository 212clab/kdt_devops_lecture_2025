# Week 2 Day 2 Session 1: 단일 컨테이너 운영의 한계점과 문제 상황

<div align="center">

**⚠️ 단일 컨테이너 한계** • **🚨 운영 문제점**

*단일 컨테이너 운영에서 발생하는 실제 문제점들 완전 이해*

</div>

---

## 🕘 세션 정보

**시간**: 09:00-09:50 (50분)  
**목표**: 단일 컨테이너 운영에서 발생하는 실제 문제점들 완전 이해  
**방식**: 문제 상황 분석 + 실제 사례 + 해결 필요성

---

## 🎯 세션 목표

### 📚 학습 목표
- **이해 목표**: 단일 컨테이너 운영에서 발생하는 실제 문제점들 완전 이해
- **적용 목표**: 실무에서 마주치는 운영 문제 상황을 예측하고 대비하는 능력
- **협업 목표**: 개별 학습 후 경험 공유 및 질의응답

### 🤔 왜 필요한가? (5분)

**현실 문제 상황**:
- 💼 **서비스 중단 사고**: 단일 컨테이너 장애로 인한 전체 서비스 다운
- 🏠 **일상 비유**: 혼자서 모든 집안일을 처리하는 것의 한계
- 📊 **시장 동향**: 99.9% 가용성 요구사항을 만족하기 어려운 단일 컨테이너

---

## 📖 핵심 개념 (35분)

### 🔍 개념 1: 가용성과 신뢰성 문제 (12분)

> **정의**: 단일 컨테이너 환경에서 발생하는 서비스 중단과 신뢰성 저하 문제

**단일 장애점 (Single Point of Failure)**:
```mermaid
graph TB
    A[사용자 요청] --> B[단일 컨테이너]
    B --> C{컨테이너 상태}
    C -->|정상| D[서비스 제공]
    C -->|장애| E[서비스 중단]
    
    F[하드웨어 장애] --> B
    G[소프트웨어 오류] --> B
    H[네트워크 문제] --> B
    I[리소스 부족] --> B
    
    style B fill:#ffebee
    style E fill:#f44336
    style D fill:#4caf50
```

### 🔍 개념 2: 확장성과 성능 한계 (12분)

> **정의**: 트래픽 증가나 부하 변동에 대응하기 어려운 단일 컨테이너의 구조적 한계

**확장성 문제**:
```mermaid
graph LR
    subgraph "트래픽 증가 시나리오"
        A[평상시<br/>100 RPS] --> B[이벤트 시<br/>1000 RPS]
        B --> C[블랙프라이데이<br/>10000 RPS]
    end
    
    subgraph "단일 컨테이너 대응"
        D[고정 리소스] --> E[성능 저하]
        E --> F[응답 지연]
        F --> G[서비스 불가]
    end
    
    A --> D
    B --> E
    C --> G
    
    style D fill:#ffebee
    style E fill:#ff9800
    style F fill:#ff9800
    style G fill:#f44336
```

### 🔍 개념 3: 운영 관리의 복잡성 (11분)

> **정의**: 수동 운영으로 인한 관리 복잡성과 인적 오류 가능성

**수동 운영의 문제점**:
- **24/7 모니터링**: 상시 감시 체계 필요
- **수동 복구**: 장애 발생 시 즉시 수동 개입
- **설정 관리**: 환경별 설정 파일 수동 관리
- **배포 위험**: 수동 배포로 인한 휴먼 에러

**실제 사고 사례 분석**:

**사례 1: 블랙프라이데이 트래픽 폭증**
- **상황**: 온라인 쇼핑몰의 블랙프라이데이 세일
- **문제**: 단일 서버로 인한 전체 서비스 마비
- **결과**: 6시간 서비스 중단, 수억 손실 $2M
- **교훈**: 자동 스케일링과 로드 밸런싱 필요

**사례 2: 데이터베이스 서버 장애**
- **상황**: 주요 데이터베이스 서버의 디스크 장애
- **문제**: 단일 장애점으로 인한 전체 애플리케이션 마비
- **결과**: 4시간 다운타임, 데이터 손실 위험
- **교훈**: 고가용성 아키텍처와 자동 페일오버 필요

**사례 3: 수동 배포 오류**
- **상황**: 수동 배포 과정에서 잘못된 설정 파일 배포
- **문제**: 전체 서비스에 잘못된 설정 적용
- **결과**: 2시간 서비스 오류, 긴급 롤백 필요
- **교훈**: 자동화된 배포와 롤링 업데이트 필요

**비용 영향 분석**:
```
단일 컨테이너 운영 비용:
- 인력 비용: 24/7 모니터링 인력 2명 ($120K/년)
- 다운타임 비용: 시간당 $10K 손실
- 인프라 비용: 과도한 리소스 프로비저닝 ($50K/년)

오케스트레이션 도입 후:
- 인력 비용: 50% 절감 ($60K/년)
- 다운타임 비용: 90% 감소 ($1K/년)
- 인프라 비용: 30% 절감 ($35K/년)

ROI: 1년 내 $84K 비용 절감
```

**장애 대응 시간 비교**:
| 상황 | 단일 컨테이너 | 오케스트레이션 |
|------|----------------|----------------|
| **장애 감지** | 5-15분 (수동) | 30초 (자동) |
| **서비스 복구** | 10-30분 | 1-2분 |
| **전체 다운타임** | 15-45분 | 1-3분 |
| **비즈니스 영향** | 심각 | 최소 |

**실시간 모니터링 시나리오**:
```bash
# 단일 컨테이너 모니터링 스크립트
#!/bin/bash
while true; do
    # 컨테이너 상태 체크
    if ! docker ps | grep -q "myapp"; then
        echo "ALERT: Container is down!" | mail -s "Service Down" admin@company.com
        # 수동 재시작 필요
        docker run -d --name myapp myapp:latest
    fi
    
    # CPU 사용률 체크
    cpu_usage=$(docker stats --no-stream myapp --format "{{.CPUPerc}}" | sed 's/%//')
    if (( $(echo "$cpu_usage > 80" | bc -l) )); then
        echo "ALERT: High CPU usage: ${cpu_usage}%" | mail -s "High CPU" admin@company.com
        # 수동 스케일링 필요
    fi
    
    sleep 60
done
```

---

## 💭 함께 생각해보기 (10분)

### 🤝 페어 토론 (5분)

**토론 주제**:
1. **장애 경험**: "서비스나 시스템 장애를 경험해본 적이 있나요?"
2. **운영 부담**: "수동으로 시스템을 관리할 때 가장 어려운 점은?"
3. **해결 방안**: "이런 문제들을 어떻게 해결할 수 있을까요?"

### 🎯 전체 공유 (5분)

- **문제 공감**: 단일 컨테이너 운영의 어려움 공유
- **해결 동기**: 오케스트레이션 필요성에 대한 동기 부여

---

## 🔑 핵심 키워드

- **Single Point of Failure (SPOF)**: 단일 장애점
- **High Availability (HA)**: 고가용성
- **Scalability**: 확장성
- **Manual Operations**: 수동 운영
- **Human Error**: 인적 오류

---

## 📝 세션 마무리

### ✅ 오늘 세션 성과
- [ ] 단일 컨테이너 운영의 한계점 이해
- [ ] 가용성과 확장성 문제 파악
- [ ] 수동 운영의 위험성 인식

### 🎯 다음 세션 준비
- **주제**: 오케스트레이션 개념과 핵심 기능
- **연결**: 문제 해결책으로서의 오케스트레이션

---

<div align="center">

**⚠️ 단일 컨테이너의 한계를 완전히 이해했습니다!**

**다음**: [Session 2 - 오케스트레이션 개념과 핵심 기능](./session_2.md)

</div>